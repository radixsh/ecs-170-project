import logging
import os
import numpy as np
import torch
from torch.utils.data import Dataset
import time

from distributions import DISTRIBUTION_FUNCTIONS
from env import CONFIG

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
console_handler = logging.StreamHandler()
logger.addHandler(console_handler)

class MyDataset(Dataset):
    def __init__(self, data, labels):
        self.data = data
        self.labels = labels

    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):
        sample = self.data[index]
        label = self.labels[index]
        return sample, label

def generate_data(count, sample_size):
    data = []

    # Generate 'count' examples uniformly at random (before, it was 9 * 'count')
    for _ in range(count):
        items = list(DISTRIBUTION_FUNCTIONS.items())
        choice = np.random.choice(len(items))
        _, dist_func = items[choice]
        points, labels = dist_func(sample_size)
        data.append((points, labels))
    return data

# TODO: multidimensional generation
# it should randomly generate N distribution types, where N is NUM_DIMENSIONS
# the function should call the randomly chosen distribution functions from distributions.py, and make an array of N-tuples out of the result
# it should also make an array of labels, which is the concatenation of the 1hot, mean and stddev of each distribution
# return a pair of those arrays
# 
# e.g., if NUM_DIMENSIONS is 2 and SAMPLE_SIZE is 3, we randomly choose 3 dimensions (say normal and gamma)
# the function should return something that looks like:
# [
#    [
#       [n1,g1],
#       [n2,g2],
#       [n3,g3]
#    ],
#    [0,0,0,0,0,0,1,0,0,normal_mean,normal_stddev,0,1,0,0,0,0,0,0,0,gamma_mean,gamma_stddev]
# ]

where n1,g1 are the first points generated by the normal dist and gamma dist, etc
def make_dataset(filename):
    start = time.time()

    raw_data = generate_data(count=CONFIG['TRAINING_SIZE'],
                             sample_size=CONFIG['SAMPLE_SIZE'])
    samples = np.array([elem[0] for elem in raw_data])
    labels = np.array([elem[1] for elem in raw_data])
    dataset = MyDataset(samples, labels)
    torch.save(dataset, filename)

    end = time.time()
    logger.info(f"Generated and saved {CONFIG['TRAINING_SIZE']} examples out "
                f"to {filename} in {end - start:.2f} seconds "
                f"(BATCH_SIZE={CONFIG['BATCH_SIZE']})")

    return dataset

# If running this file directly as a script, then generate some training
# examples and save them to a file for later use
if __name__ == "__main__":
    data_directory = 'data'
    os.makedirs(data_directory, exist_ok=True)

    make_dataset('data/train_dataset')
    make_dataset('data/test_dataset')
